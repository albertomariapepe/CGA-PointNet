{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albertomariapepe/CGA-PointNet/blob/main/CGA_PoseNet_(Cambridge_Landmarks).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNmZCKUmcWM-"
      },
      "source": [
        "# Defining CGA-PoseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ1oXFXlt0-G"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.layers.merge import concatenate\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "#Loading GoogLeNet with ImageNet weights\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "model = InceptionV3(classifier_activation = None, weights = \"imagenet\", input_tensor=Input(shape=(224, 224, 3)))\n",
        "# summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eap2YxT5KNPv"
      },
      "outputs": [],
      "source": [
        "#modifying the last layer\n",
        "\n",
        "x2 = tf.keras.layers.Dense(2048)(model.layers[-1].output)\n",
        "output2 = tf.keras.layers.Dense(8)(x2)\n",
        "CGAPoseNet = tf.keras.Model(inputs=model.input, outputs=output2)\n",
        "CGAPoseNet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wCNz8twcZ9D"
      },
      "source": [
        "# Converting Camera Poses into Motors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_59LfNqDLTD"
      },
      "outputs": [],
      "source": [
        "FOLDER = \"KingsCollege\" #Change the name to change the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlI5XNDYcbFj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZG1xqTUIS7i"
      },
      "outputs": [],
      "source": [
        "!pip install clifford"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAzn_xo4omZv"
      },
      "outputs": [],
      "source": [
        "from clifford.g3c import *\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "lambda_coeff = 200\n",
        "\n",
        "#functions to convert quaternions coefficients into to GA rotors\n",
        "def q2S(*args):\n",
        "    '''\n",
        "    convert tuple of quaternion coefficients to a spinor'''\n",
        "    q = args\n",
        "    return q[0] + q[1]*e13 +q[2]*e23 + q[3]*e12\n",
        "\n",
        "#From Euclidean to 1D Up CGA. \n",
        "#function implementing Eq. 6 (convert a vector in Euclidean space into a rotor \n",
        "#in spherical space)\n",
        "def translation_rotor(a, L = lambda_coeff):\n",
        "    Ta = (L + a*e4)/(sqrt(L**2 + a**2))\n",
        "    return Ta\n",
        "\n",
        "#From Euclidean to 1D Up CGA. function implementing the Eq. 10 (X = f(x))\n",
        "def up1D(x, L = lambda_coeff):\n",
        "    Y = (2*L / (L**2 + x**2))*x + ((L**2-x**2)/(L**2 + x**2))*e4\n",
        "    return Y\n",
        "\n",
        "#From 1D Up CGA to Euclidean. function implementing the inverse of Eq. 10 (x = f^{-1}(X))\n",
        "def down1D(Y, x, L = lambda_coeff):\n",
        "    alpha = (2*L/(L**2 + x**2))\n",
        "    beta  =  (L**2 - x**2)/(L**2 + x**2)\n",
        "    x = (Y - beta*e4)/alpha\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9z1OIujeO4y"
      },
      "outputs": [],
      "source": [
        "#reads the dataset labels and converts them into motors (Train set)\n",
        "\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_train.txt\").readlines()\n",
        "newfile = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\", \"w\")\n",
        "\n",
        "position_train = []\n",
        "\n",
        "for i in range(0,3):\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "for i in range(3, len(list_of_lines)):\n",
        "\n",
        "    a = []\n",
        "    a = list_of_lines[i].split()\n",
        "\n",
        "    position_train = np.append(position_train, [float(a[1]), float(a[2]), float(a[3])])\n",
        "\n",
        "    Ta = translation_rotor(float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3)\n",
        "    R = q2S(float(a[4]), float(a[5]), float(a[6]), float(a[7]))\n",
        "\n",
        "    M = Ta*R\n",
        "    \n",
        "    a[1] = M[0] \n",
        "    a[2] = M[6]\n",
        "    a[3] = M[7]\n",
        "    a[4] = M[8]\n",
        "    a[5] = M[10]\n",
        "    a[6] = M[11]\n",
        "    a[7] = M[13]\n",
        "    a.append(M[26])\n",
        "\n",
        "    b = \" \".join(map(str, a))\n",
        "    list_of_lines[i] = b\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "    if i == 3:\n",
        "        print(a)\n",
        "        print(list_of_lines[i])\n",
        "\n",
        "print(i)\n",
        "position_train = np.reshape(position_train, (-1, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Train-Test Data"
      ],
      "metadata": {
        "id": "BLTMEMV5h2Fl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Y1NTRSgKyW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        " \n",
        "x_train = []\n",
        "\n",
        "#reads the dataset frames, reshapes them and normalizes them  (Train Set)\n",
        "\n",
        "list_train = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\").readlines() # no need for closing, python will do it for you\n",
        "print(len(list_train))\n",
        "for i in range(6,len(list_train)):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    a = list_train[i].split()\n",
        "    img = cv2.imread(\"/content/drive/MyDrive/\"+ FOLDER + \"/\" + a[0])\n",
        "    \n",
        "    resized = cv2.resize(img, (224, 224))\n",
        "    normalized = cv2.normalize(resized, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "\n",
        "    x_train = np.append(x_train, normalized)\n",
        "\n",
        "\n",
        "# Output img with window name as 'image'\n",
        "#cv2_imshow(img)\n",
        "cv2_imshow(resized)\n",
        "\n",
        "np.save(\"x_train.npy\", x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7i6RyhLeN6H"
      },
      "outputs": [],
      "source": [
        "#reads the dataset labels and converts them into motors (Test Set)\n",
        "\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "newfile = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_test.txt\", \"w\")\n",
        "\n",
        "position_test = []\n",
        "for i in range(0,3):\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "for i in range(3, len(list_of_lines)):\n",
        "\n",
        "    a = []\n",
        "    a = list_of_lines[i].split()\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    position_test = np.append(position_test, [float(a[1]), float(a[2]), float(a[3])])\n",
        "\n",
        "\n",
        "    Ta = translation_rotor(float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3)\n",
        "    R = q2S(float(a[4]), float(a[5]), float(a[6]), float(a[7]))\n",
        "\n",
        "    M = Ta*R\n",
        "    \n",
        "    a[1] = M[0] \n",
        "    a[2] = M[6]\n",
        "    a[3] = M[7]\n",
        "    a[4] = M[8]\n",
        "    a[5] = M[10]\n",
        "    a[6] = M[11]\n",
        "    a[7] = M[13]\n",
        "    a.append(M[26])\n",
        "\n",
        "    #print(a)\n",
        "\n",
        "    b = \" \".join(map(str, a))\n",
        "    list_of_lines[i] = b\n",
        "    newfile.write(list_of_lines[i])\n",
        "    newfile.write(\"\\n\")\n",
        "\n",
        "    if i == 3:\n",
        "        print(a)\n",
        "        print(list_of_lines[i])\n",
        "\n",
        "position_test = np.reshape(position_test, (-1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy9eNCuDh2zz"
      },
      "outputs": [],
      "source": [
        "x_test = []\n",
        "\n",
        "#reads the dataset frames, reshapes them and normalizes them  (Train Set)\n",
        "\n",
        "list_test = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_test.txt\").readlines() \n",
        "print(len(list_test))\n",
        "for i in range(6, len(list_test)):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    a = list_test[i].split()\n",
        "\n",
        "    img = cv2.imread(\"/content/drive/MyDrive/\"+ FOLDER + \"/\" + a[0])\n",
        "    resized = cv2.resize(img, (224, 224))\n",
        "    normalized = cv2.normalize(resized, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "    x_test = np.append(x_test, normalized)\n",
        " \n",
        "\n",
        "cv2_imshow(resized)\n",
        "\n",
        "np.save(\"x_test.npy\", x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7JGTSlSqIUD"
      },
      "outputs": [],
      "source": [
        "y_train = []\n",
        "\n",
        "#loads train and test labels in motor form\n",
        "\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_train.txt\").readlines()\n",
        "for i in range(6, len(list_of_lines)):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    a = list_of_lines[i].split()\n",
        "\n",
        "    y_train = np.append(y_train, float(a[1]))\n",
        "    y_train = np.append(y_train, float(a[2]))\n",
        "    y_train = np.append(y_train, float(a[3]))\n",
        "    y_train = np.append(y_train, float(a[4]))\n",
        "    y_train = np.append(y_train, float(a[5]))\n",
        "    y_train = np.append(y_train, float(a[6]))\n",
        "    y_train = np.append(y_train, float(a[7]))\n",
        "    y_train = np.append(y_train, float(a[8]))\n",
        "\n",
        "\n",
        "print(\"****\")\n",
        "y_test = []\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/new_dataset_test.txt\").readlines()\n",
        "for i in range(6, len(list_of_lines)):\n",
        "    if i % 100 == 0:\n",
        "        print(i)\n",
        "    a = list_of_lines[i].split()\n",
        "    y_test = np.append(y_test, float(a[1]))\n",
        "    y_test = np.append(y_test, float(a[2]))\n",
        "    y_test = np.append(y_test, float(a[3]))\n",
        "    y_test = np.append(y_test, float(a[4]))\n",
        "    y_test = np.append(y_test, float(a[5]))\n",
        "    y_test = np.append(y_test, float(a[6]))\n",
        "    y_test = np.append(y_test, float(a[7]))\n",
        "    y_test = np.append(y_test, float(a[8]))\n",
        "\n",
        "\n",
        "np.save(\"y_train.npy\", y_train)\n",
        "np.save(\"y_test.npy\", y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuhTJj_Vq_jy"
      },
      "outputs": [],
      "source": [
        "#224 x 224 x 3 is the size of each frame\n",
        "x_train = np.reshape(x_train, (-1, 224, 224, 3)) \n",
        "x_test = np.reshape(x_test, (-1, 224, 224, 3))\n",
        "\n",
        "#8 is the number of motor coefficients\n",
        "y_train = np.reshape(y_train, (-1, 8)) \n",
        "y_test = np.reshape(y_test, (-1, 8))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the camera pose in Euclidean (original ground truth) and spherical space\n",
        "#If Lambda is chose large enough, the two traces should match\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "origin = e4\n",
        "\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "trans_GA = []\n",
        "trans_GT = []\n",
        "\n",
        "position = position_train\n",
        "\n",
        "positional_error = []\n",
        "\n",
        "T_or = []\n",
        "T_pred = []\n",
        "for i in range(len(y_train)):\n",
        "    x = 1\n",
        "\n",
        "    X = y_train[i]\n",
        "\n",
        "    M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "\n",
        "    T = M_real * origin * ~M_real\n",
        "    t = down1D(T, x)\n",
        "\n",
        "    mae = np.mean(np.abs(np.array([t[1], t[2], t[3]]) - np.array([position[i,0], position[i,1], position[i,2]])))\n",
        "\n",
        "    positional_error  = np.append(positional_error , mae)\n",
        "\n",
        "    trans_GA = np.append(trans_GA, np.array([t[1], t[2], t[3]]))\n",
        "    trans_GT = np.append(trans_GT, np.array([position[i,0], position[i,1], position[i,2]]))\n",
        "\n",
        "    ax.scatter(t[1], t[2], t[3], s = 20, c = \"r\")\n",
        "    ax.scatter(position[i,0], position[i,1], position[i,2], s = 20, c = \"b\", alpha = 0.5)\n",
        "\n",
        "    T_or = np.append(T_or, [t[1], t[2], t[3]])\n",
        "    T_pred = np.append(T_pred, [position[i,0], position[i,1], position[i,2]])\n",
        "\n",
        "\n",
        "ax.set_xlabel(\"X\", fontsize = 40.0)\n",
        "ax.set_ylabel(\"Y\", fontsize = 40.0)\n",
        "ax.set_zlabel(\"Z\", fontsize = 40.0)\n",
        "\n",
        "plt.show()       "
      ],
      "metadata": {
        "id": "RNAX4_asLFar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSZ-aPFjsRfj"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7o1rSZyrsmQ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue9UxWZ5r1-m"
      },
      "outputs": [],
      "source": [
        "#defining hyperparameters\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 64 \n",
        "\n",
        "initial_learning_rate = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.90,\n",
        "    staircase=True)\n",
        "\n",
        "#compiling the model\n",
        "CGAPoseNet.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "                 loss=\"mse\", run_eagerly=True)\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "#training\n",
        "model_train = CGAPoseNet.fit(x = x_train, y =y_train,\n",
        "                           validation_split = 0.2,\n",
        "                            epochs=nb_epoch,\n",
        "                            verbose=1,\n",
        "                            shuffle=True,\n",
        "                            callbacks = es_callback,\n",
        "                            batch_size=batch_size)\n",
        "\n",
        "#plotting losses\n",
        "loss = model_train.history['loss']\n",
        "val_loss = model_train.history['val_loss']\n",
        "epochs = range(0,np.size(loss))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'b-', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by0gFJhDS3TL"
      },
      "outputs": [],
      "source": [
        "#storing losses\n",
        "np.save(\"train_loss.npy\", loss)\n",
        "np.save(\"val_loss.npy\", val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z245LMHDTFn-"
      },
      "outputs": [],
      "source": [
        "#saving weights\n",
        "CGAPoseNet.save('weights.h5')\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSwIlA-Rv96v"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCX25ZCxq8IY"
      },
      "outputs": [],
      "source": [
        "#model = keras.models.load_model('weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Cstcq9tTw9"
      },
      "outputs": [],
      "source": [
        "#prediction step\n",
        "y_pred = CGAPoseNet.predict(x_test)\n",
        "np.save(\"y_pred.npy\", y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uDZIY03tZ-M"
      },
      "outputs": [],
      "source": [
        "#Storing the MSE between \\hat{M}, M over the test set\n",
        "\n",
        "MSE = []\n",
        "\n",
        "tot = 0\n",
        "cnt = 0\n",
        "for i in range(len(y_test)):\n",
        "    mse = (np.square(y_test[i] - y_pred[i])).mean()\n",
        "    \n",
        "    MSE = np.append(MSE, mse)\n",
        "\n",
        "    #printing the first 20 motors M, \\hat{M} if the MSE between them is close \n",
        "    if cnt < 20 and mse < 0.0008:\n",
        "        print(\"original:\" , y_test)\n",
        "\n",
        "        X = y_test[i]\n",
        "        Y = y_pred[i]\n",
        "\n",
        "        M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "        M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "        print(\"prediction:\", y_pred[i])\n",
        "        print(\"****\")\n",
        "        cnt += 1\n",
        "    \n",
        "    tot += mse\n",
        "\n",
        "\n",
        "print(tot)\n",
        "np.save(\"MSE.npy\", MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqUB90KBg0lH"
      },
      "outputs": [],
      "source": [
        "#evaluating positional and rotational error (see Section 4.4 Metrics)\n",
        "\n",
        "origin = e4\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "list_of_lines = open(\"/content/drive/MyDrive/\"+ FOLDER + \"/dataset_test.txt\").readlines() # no need for closing, python will do it for you\n",
        "\n",
        "positional_error = []\n",
        "rotational_error = []\n",
        "\n",
        "translation = []\n",
        "translation_pred = []\n",
        "\n",
        "rotation = []\n",
        "rotation_pred = []\n",
        "for i in range(len(y_test)):\n",
        "    a = []\n",
        "    a = list_of_lines[i+3].split()\n",
        "\n",
        "    #x is required by the function down1D\n",
        "    x = float(a[1])*e1 + float(a[2])*e2 + float(a[3])*e3\n",
        "\n",
        "    X = y_test[i]\n",
        "    Y = y_pred[i]\n",
        "\n",
        "    #construct M and \\hat{M}\n",
        "    M_real = X[0] + X[1]*e12 + X[2]*e13 + X[3]*e14 + X[4]*e23 + X[5]*e24 + X[6]*e34 + X[7]*e1234\n",
        "    M_pred = Y[0] + Y[1]*e12 + Y[2]*e13 + Y[3]*e14 + Y[4]*e23 + Y[5]*e24 + Y[6]*e34 + Y[7]*e1234\n",
        "\n",
        "    #normalizing\n",
        "    M_pred = M_pred / sqrt((M_pred* ~M_pred)[0])\n",
        "\n",
        "    #predicted and real displacement vector \\hat{D}, D in spherical space\n",
        "    S = M_pred * origin * ~M_pred\n",
        "    T = M_real * origin * ~M_real\n",
        "\n",
        "    #predicted and real displacement vector \\hat{d}, d in Euclidean space\n",
        "    s = down1D(S, x)\n",
        "    t = down1D(T, x)\n",
        "\n",
        "    #POSITIONAL ERROR\n",
        "    mae = np.mean(np.abs(np.array([t[1], t[2], t[3]]) - np.array([s[1], s[2], s[3]])))\n",
        "\n",
        "    positional_error  = np.append(positional_error , mae)\n",
        "\n",
        "    translation = np.append(translation, np.array([t[1], t[2], t[3]]))\n",
        "    translation_pred = np.append(translation_pred, np.array([s[1], s[2], s[3]]))\n",
        "\n",
        "\n",
        "    #plotting the camera trace\n",
        "    ax.scatter(t[1], t[2], t[3], s = 20, c = \"r\")\n",
        "    ax.scatter(s[1], s[2], s[3], s = 20, c = \"b\", alpha = 0.5)\n",
        "\n",
        "    Tup = translation_rotor(t[1]*e1 + t[2]*e2 + t[3]*e3)\n",
        "    Sup = translation_rotor(s[1]*e1 + s[2]*e2 + s[3]*e3)\n",
        "\n",
        "    #predicted and real rotors \\hat{R}, R\n",
        "    R_pred = ~Sup* M_pred \n",
        "    R_real = ~Tup* M_real\n",
        "\n",
        "    if (R_real * ~R_pred)[0] > 1:\n",
        "        error = (np.arccos(1))*360/(2*np.pi)\n",
        "    elif (R_real * ~R_pred)[0] < -1:\n",
        "        error = (np.arccos(-1))*360/(2*np.pi)\n",
        "    else:\n",
        "        #ROTATIONAL ERROR\n",
        "        error = (np.arccos((R_real * ~R_pred)[0]))*360/(2*np.pi)\n",
        "\n",
        "    rotational_error = np.append(rotational_error, error)\n",
        "\n",
        "    rotation = np.append(rotation, np.array([R_real[0], R_real[6], R_real[7], R_real[10]]))\n",
        "    rotation_pred = np.append(rotation_pred, np.array([R_pred[0], R_pred[6], R_pred[7], R_pred[10]]))\n",
        " \n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#storing rotational and translational errors\n",
        "np.save(\"translation_error.npy\", positional_error)\n",
        "np.save(\"rotational_error.npy\", rotational_error)\n",
        "\n",
        "#storing original and predicted translations\n",
        "np.save(\"T.npy\", translation)\n",
        "np.save(\"S.npy\", translation_pred) \n",
        "\n",
        "#storing original and predicted rotations\n",
        "np.save(\"R.npy\", rotation)\n",
        "np.save(\"Q.npy\", rotation_pred)          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM7s2ENa6_Jd"
      },
      "outputs": [],
      "source": [
        "#plotting the camera orientation (coefficients e_{12}, e_{13}, e_{23} of rotor R)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "\n",
        "N=200\n",
        "stride=1\n",
        "\n",
        "u = np.linspace(0, 2 * np.pi, N)\n",
        "v = np.linspace(0, np.pi, N)\n",
        "x = np.outer(np.cos(u), np.sin(v))\n",
        "y = np.outer(np.sin(u), np.sin(v))\n",
        "z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
        "ax.plot_surface(x, y, z, linewidth=0.0, alpha = 0.1, cstride=stride, rstride=stride)\n",
        "\n",
        "ax.scatter(0, 0, 0, c = \"k\", marker = \"s\", label = \"O\")\n",
        "\n",
        "rotation = np.reshape(rotation, (-1, 4))\n",
        "rotation_pred = np.reshape(rotation_pred, (-1, 4))\n",
        "ax.scatter(rotation[:,1], rotation[:, 2], rotation[:,3], s = 15, c = \"r\")\n",
        "ax.scatter(rotation_pred[:,1], rotation_pred[:, 2], rotation_pred[:,3], s = 15, c = \"b\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8oUyqs82rlv"
      },
      "outputs": [],
      "source": [
        "print(np.median(positional_error))\n",
        "print(np.mean(  positional_error))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYMZoh-t2tB4"
      },
      "outputs": [],
      "source": [
        "print(np.median(rotational_error))\n",
        "print(np.mean(  rotational_error))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CGA-PoseNet (Cambridge Landmarks).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}